---
# This playbook installs and configures Apache Spark

- file:
    path: /hadoop/spark
    state: directory
    mode: 0755


- unarchive:
    src: "{{ tarball_dest_path }}/{{ spark_binary_name }}"
    dest: /hadoop/spark
    remote_src: True
    extra_opts: "--strip-components=1"
    creates: /hadoop/spark/LICENSE

- name: Configure profile
  template: src=profile.j2 dest=/etc/profile.d/spark.sh
  tags: hadoop

- name: Configure Spark environment file
  template: src=spark-env.j2 dest=/hadoop/spark/conf/spark-env.sh mode=0755
  tags: hadoop

- file:
    src: /hadoop/share/hadoop/tools/lib/hadoop-aws-{{ hadoop_version }}.jar
    dest: /hadoop/spark/jars/hadoop-aws-{{ hadoop_version }}.jar
    state: link

- name: Get aws-java-sdk*.jar file names
  shell: "cd /hadoop/share/hadoop/tools/lib ; ls aws-java-sdk*"
  register: aws_java_sdk_jar_name

- file:
    src: /hadoop/share/hadoop/tools/lib/{{ item }}
    dest: /hadoop/spark/jars/{{ item }} 
    state: link
  with_items: "{{ aws_java_sdk_jar_name.stdout_lines }}"

- name: Configure hive-site file
  template: src=hive-site.j2 dest=/hadoop/spark/conf/hive-site.xml
  tags: hive
  when:
  - head_group in group_names
